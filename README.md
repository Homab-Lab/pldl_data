# Data used for Population Level Label Distribution Learning Experiments

The datasets were used to evaluate PLDL discussed in these papers.
```
@inproceedings{Liu2019HCOMP,
author = {Liu, Tong and Venkatachalam, Akash and Bongale, Pratik Sanjay and Homan, Christopher M.},
booktitle = {Seventh AAAI Conference on Human Computation and Crowdsourcing},
title = {{Learning to Predict Population-Level Label Distributions}},
year = {2019},
  volume={7},
  number={1},
  pages={68--76},
note={A preliminary version appears in \cite{Liu2019}},
}

@inproceedings{Liu2019,
 author = {Liu, Tong and Venkatachalam, Akash and Sanjay Bongale, Pratik and Homan, Christopher},
 title = {Learning to Predict Population-Level Label Distributions},
 booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
 series = {WWW '19},
 year = {2019},
 isbn = {978-1-4503-6675-5},
 location = {San Francisco, USA},
 pages = {1111--1120},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3308560.3317082},
 doi = {10.1145/3308560.3317082},
 acmid = {3317082},
 publisher = {ACM},
 keywords = {Subjectivity in crowdsourcing, clustering and classification, label distribution learning, social media.},
} 
```

# Citations for Jobs Dataset

```
@inproceedings{Liu2016,
    title = "Understanding Discourse on Work and Job-Related Well-Being in Public Social Media",
    author = "Liu, Tong  and
      Homan, Christopher  and
      Ovesdotter Alm, Cecilia  and
      Lytle, Megan  and
      Marie White, Ann  and
      Kautz, Henry",
    booktitle = "Proceedings of the 54th Annual Meeting of the ACL",
    year = "2016",
}
```

# Citation for Suicide Related Dataset

```
@article{Liu2017,
abstract = {Suicide is an important but often misunderstood problem, one that researchers are now seeking to better understand through social media. Due in large part to the fuzzy nature of what constitutes suicidal risks, most supervised approaches for learning to automatically detect suicide-related activity in social media require a great deal of human labor to train. However, humans themselves have diverse or conflicting views on what constitutes suicidal thoughts. So how to obtain reliable gold standard labels is fundamentally challenging and, we hypothesize, depends largely on what is asked of the annotators and what slice of the data they label. We conducted multiple rounds of data labeling and collected annotations from crowdsourcing workers and domain experts. We aggregated the resulting labels in various ways to train a series of supervised models. Our preliminary evaluations show that using unanimously agreed labels from multiple annotators is helpful to achieve robust machine models.},
archivePrefix = {arXiv},
arxivId = {1701.08796},
author = {Liu, Tong and Cheng, Qijin and Homan, Christopher M and Silenzio, Vincent M B},
eprint = {1701.08796},
keywords = {crowd-,humans-in-the-loop,social media,suicide prevention},
title = {{Learning from various labeling strategies for suicide-related messages on social media: An experimental study}},
url = {http://arxiv.org/abs/1701.08796},
year = {2017}
}
```
